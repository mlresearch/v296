---
title: Impact of Task Phrasing on Presumptions in Large Language Models
abstract: Concerns with the safety and reliability of applying large-language models
  (LLMs) in unpredictable real-world applications motivate this study, which examines
  how task phrasing can lead to presumptions in LLMs, making it difficult for them
  to adapt when the task deviates from these assumptions. We investigated the impact
  of these presumptions on the performance of LLMs using the iterated prisonerâ€™s dilemma
  as a case study. Our experiments reveal that LLMs are susceptible to presumptions
  when making decisions even with reasoning steps. However, when the task phrasing
  was neutral, the models demonstrated logical reasoning without much presumptions.
  These findings highlight the importance of proper task phrasing to reduce the risk
  of presumptions in LLMs.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: ong25a
month: 0
tex_title: Impact of Task Phrasing on Presumptions in Large Language Models
firstpage: 67
lastpage: 74
page: 67-74
order: 67
cycles: false
bibtex_author: Ong, Kenneth J. K.
author:
- given: Kenneth J. K.
  family: Ong
date: 2025-08-12
address:
container-title: 'Proceedings on "I Can''t Believe It''s Not Better: Challenges in
  Applied Deep Learning" at ICLR 2025 Workshops'
volume: '296'
genre: inproceedings
issued:
  date-parts:
  - 2025
  - 8
  - 12
pdf: https://raw.githubusercontent.com/mlresearch/v296/main/assets/ong25a/ong25a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
